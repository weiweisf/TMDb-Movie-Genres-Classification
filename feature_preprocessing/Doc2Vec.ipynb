{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/tmdb_5000_movies_nonull.csv')\n",
    "df_credits = pd.read_csv('dataset/tmdb_5000_credits.csv')\n",
    "credits_sub = df_credits.loc[:, ['movie_id', 'cast']].rename(columns={\n",
    "                                                             'movie_id': 'id'})\n",
    "\n",
    "df = df[['id', 'budget', 'genres', 'keywords', 'original_language',\n",
    "         'overview', 'popularity', 'production_companies',\n",
    "         'production_countries', 'release_date', 'revenue', 'runtime',\n",
    "         'spoken_languages', 'tagline', 'title', 'vote_average', 'vote_count']]\n",
    "df = df.merge(credits_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/subtitles/subtitles.json', 'r') as f:\n",
    "    sub_dict = json.load(f)\n",
    "sub_dict = defaultdict(str, sub_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4799, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[\"subtitles\"] = df.title.apply(lambda title: sub_dict[title]) # keep blocks separated\n",
    "df[\"subtitles\"] = df.title.apply(\n",
    "    lambda title: \"\\n\\n\".join(sub_dict[title]))  # single string\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3956, 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop movies with no genre info\n",
    "for i, row in df.iterrows():\n",
    "    if row['genres'] == '[]':\n",
    "        df.drop(i, inplace=True)\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3037, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>cast</th>\n",
       "      <th>subtitles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3032</th>\n",
       "      <td>226458</td>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 53, \"name\": \"Thriller\"}, {\"id\": 27, \"n...</td>\n",
       "      <td>[{\"id\": 9712, \"name\": \"possession\"}]</td>\n",
       "      <td>en</td>\n",
       "      <td>During an all-night, drug-fueled party at an a...</td>\n",
       "      <td>3.619167</td>\n",
       "      <td>[{\"name\": \"GO Productions\", \"id\": 2943}, {\"nam...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2015-01-16</td>\n",
       "      <td>0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>nederlands</td>\n",
       "      <td>Backmask</td>\n",
       "      <td>4.7</td>\n",
       "      <td>79</td>\n",
       "      <td>[{\"cast_id\": 3, \"character\": \"Father Conway\", ...</td>\n",
       "      <td>The Exeter School for\\nthe feeble minded.\\n\\nT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033</th>\n",
       "      <td>692</td>\n",
       "      <td>12000</td>\n",
       "      <td>[{\"id\": 27, \"name\": \"Horror\"}, {\"id\": 35, \"nam...</td>\n",
       "      <td>[{\"id\": 237, \"name\": \"gay\"}, {\"id\": 900, \"name...</td>\n",
       "      <td>en</td>\n",
       "      <td>Notorious Baltimore criminal and underground f...</td>\n",
       "      <td>4.553644</td>\n",
       "      <td>[{\"name\": \"Dreamland Productions\", \"id\": 407}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>1972-03-12</td>\n",
       "      <td>6000000</td>\n",
       "      <td>93.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>An exercise in poor taste.</td>\n",
       "      <td>Pink Flamingos</td>\n",
       "      <td>6.2</td>\n",
       "      <td>110</td>\n",
       "      <td>[{\"cast_id\": 8, \"character\": \"Divine / Babs Jo...</td>\n",
       "      <td>Hello, moviegoers.\\nThis is Mr. Jag...\\n\\nspea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034</th>\n",
       "      <td>124606</td>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 18, \"name\": \"Drama\"}]</td>\n",
       "      <td>[{\"id\": 10726, \"name\": \"gang\"}, {\"id\": 33928, ...</td>\n",
       "      <td>en</td>\n",
       "      <td>A young woman in L.A. is having a bad day: she...</td>\n",
       "      <td>0.918116</td>\n",
       "      <td>[{\"name\": \"Asylum Films\", \"id\": 10571}, {\"name...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>1995-09-09</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Sometimes you've got to break the rules</td>\n",
       "      <td>Bang</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[{\"cast_id\": 2, \"character\": \"The Girl\", \"cred...</td>\n",
       "      <td>All right, Saturday\\nis the big day.\\n\\nA lot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>14337</td>\n",
       "      <td>7000</td>\n",
       "      <td>[{\"id\": 878, \"name\": \"Science Fiction\"}, {\"id\"...</td>\n",
       "      <td>[{\"id\": 1448, \"name\": \"distrust\"}, {\"id\": 2101...</td>\n",
       "      <td>en</td>\n",
       "      <td>Friends/fledgling entrepreneurs invent a devic...</td>\n",
       "      <td>23.307949</td>\n",
       "      <td>[{\"name\": \"Thinkfilm\", \"id\": 446}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2004-10-08</td>\n",
       "      <td>424760</td>\n",
       "      <td>77.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>What happens if it actually works?</td>\n",
       "      <td>Primer</td>\n",
       "      <td>6.9</td>\n",
       "      <td>658</td>\n",
       "      <td>[{\"cast_id\": 1, \"character\": \"Aaron\", \"credit_...</td>\n",
       "      <td>Here's what's going to happen.\\nI'm going to r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036</th>\n",
       "      <td>9367</td>\n",
       "      <td>220000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...</td>\n",
       "      <td>[{\"id\": 5616, \"name\": \"united states\\u2013mexi...</td>\n",
       "      <td>es</td>\n",
       "      <td>El Mariachi just wants to play his guitar and ...</td>\n",
       "      <td>14.269792</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"MX\", \"name\": \"Mexico\"}, {\"iso...</td>\n",
       "      <td>1992-09-04</td>\n",
       "      <td>2040920</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{\"iso_639_1\": \"es\", \"name\": \"Espa\\u00f1ol\"}]</td>\n",
       "      <td>He didn't come looking for trouble, but troubl...</td>\n",
       "      <td>El Mariachi</td>\n",
       "      <td>6.6</td>\n",
       "      <td>238</td>\n",
       "      <td>[{\"cast_id\": 1, \"character\": \"El Mariachi\", \"c...</td>\n",
       "      <td>Yes.\\n\\nYes.\\n\\nYou know what to do.\\n\\nGood m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  budget                                             genres  \\\n",
       "3032  226458       0  [{\"id\": 53, \"name\": \"Thriller\"}, {\"id\": 27, \"n...   \n",
       "3033     692   12000  [{\"id\": 27, \"name\": \"Horror\"}, {\"id\": 35, \"nam...   \n",
       "3034  124606       0                      [{\"id\": 18, \"name\": \"Drama\"}]   \n",
       "3035   14337    7000  [{\"id\": 878, \"name\": \"Science Fiction\"}, {\"id\"...   \n",
       "3036    9367  220000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...   \n",
       "\n",
       "                                               keywords original_language  \\\n",
       "3032               [{\"id\": 9712, \"name\": \"possession\"}]                en   \n",
       "3033  [{\"id\": 237, \"name\": \"gay\"}, {\"id\": 900, \"name...                en   \n",
       "3034  [{\"id\": 10726, \"name\": \"gang\"}, {\"id\": 33928, ...                en   \n",
       "3035  [{\"id\": 1448, \"name\": \"distrust\"}, {\"id\": 2101...                en   \n",
       "3036  [{\"id\": 5616, \"name\": \"united states\\u2013mexi...                es   \n",
       "\n",
       "                                               overview  popularity  \\\n",
       "3032  During an all-night, drug-fueled party at an a...    3.619167   \n",
       "3033  Notorious Baltimore criminal and underground f...    4.553644   \n",
       "3034  A young woman in L.A. is having a bad day: she...    0.918116   \n",
       "3035  Friends/fledgling entrepreneurs invent a devic...   23.307949   \n",
       "3036  El Mariachi just wants to play his guitar and ...   14.269792   \n",
       "\n",
       "                                   production_companies  \\\n",
       "3032  [{\"name\": \"GO Productions\", \"id\": 2943}, {\"nam...   \n",
       "3033     [{\"name\": \"Dreamland Productions\", \"id\": 407}]   \n",
       "3034  [{\"name\": \"Asylum Films\", \"id\": 10571}, {\"name...   \n",
       "3035                 [{\"name\": \"Thinkfilm\", \"id\": 446}]   \n",
       "3036           [{\"name\": \"Columbia Pictures\", \"id\": 5}]   \n",
       "\n",
       "                                   production_countries release_date  revenue  \\\n",
       "3032  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2015-01-16        0   \n",
       "3033  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   1972-03-12  6000000   \n",
       "3034  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   1995-09-09        0   \n",
       "3035  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2004-10-08   424760   \n",
       "3036  [{\"iso_3166_1\": \"MX\", \"name\": \"Mexico\"}, {\"iso...   1992-09-04  2040920   \n",
       "\n",
       "      runtime                               spoken_languages  \\\n",
       "3032     91.0       [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "3033     93.0       [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "3034     98.0       [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "3035     77.0       [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "3036     81.0  [{\"iso_639_1\": \"es\", \"name\": \"Espa\\u00f1ol\"}]   \n",
       "\n",
       "                                                tagline           title  \\\n",
       "3032                                         nederlands        Backmask   \n",
       "3033                         An exercise in poor taste.  Pink Flamingos   \n",
       "3034            Sometimes you've got to break the rules            Bang   \n",
       "3035                 What happens if it actually works?          Primer   \n",
       "3036  He didn't come looking for trouble, but troubl...     El Mariachi   \n",
       "\n",
       "      vote_average  vote_count  \\\n",
       "3032           4.7          79   \n",
       "3033           6.2         110   \n",
       "3034           6.0           1   \n",
       "3035           6.9         658   \n",
       "3036           6.6         238   \n",
       "\n",
       "                                                   cast  \\\n",
       "3032  [{\"cast_id\": 3, \"character\": \"Father Conway\", ...   \n",
       "3033  [{\"cast_id\": 8, \"character\": \"Divine / Babs Jo...   \n",
       "3034  [{\"cast_id\": 2, \"character\": \"The Girl\", \"cred...   \n",
       "3035  [{\"cast_id\": 1, \"character\": \"Aaron\", \"credit_...   \n",
       "3036  [{\"cast_id\": 1, \"character\": \"El Mariachi\", \"c...   \n",
       "\n",
       "                                              subtitles  \n",
       "3032  The Exeter School for\\nthe feeble minded.\\n\\nT...  \n",
       "3033  Hello, moviegoers.\\nThis is Mr. Jag...\\n\\nspea...  \n",
       "3034  All right, Saturday\\nis the big day.\\n\\nA lot ...  \n",
       "3035  Here's what's going to happen.\\nI'm going to r...  \n",
       "3036  Yes.\\n\\nYes.\\n\\nYou know what to do.\\n\\nGood m...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df[df[\"subtitles\"] == ''].index, inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "print(df.shape)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_words(text):\n",
    "    # remove punctuation and whitespace\n",
    "    # but keep hyphens and apostrophes\n",
    "    filtered_text = re.sub(r'[^\\w\\'\\s-]',\n",
    "                           '', text)\n",
    "    return word_tokenize(filtered_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 45s, sys: 932 ms, total: 1min 46s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "idxs = df.id.tolist()\n",
    "%time sub_words = [text_to_words(text) for text in df.subtitles.tolist()]\n",
    "subs = dict(zip(idxs, sub_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 372 ms, sys: 4 ms, total: 376 ms\n",
      "Wall time: 374 ms\n"
     ]
    }
   ],
   "source": [
    "%time tagged_data = [TaggedDocument(words=word_list, tags=[index]) for index, word_list in subs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.4 s, sys: 92 ms, total: 12.5 s\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec(vector_size=50, min_count=2, workers=4)\n",
    "%time model.build_vocab(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.52 s, sys: 12 ms, total: 6.54 s\n",
      "Wall time: 6.56 s\n"
     ]
    }
   ],
   "source": [
    "word2vec = Word2Vec(size=50)\n",
    "%time word2vec.build_vocab([word for text in tagged_data for word in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download glove.6B.50d.txt from\n",
    "# https://www.kaggle.com/rtatman/glove-global-vectors-for-word-representation/version/1\n",
    "# run following command to convert to word2vec format (extra line at the top)\n",
    "# python -m gensim.scripts.glove2word2vec -i glove.6B.50d.txt -o glove.6B.50d.word2vec.txt\n",
    "# https://github.com/RaRe-Technologies/gensim/blob/4543646d3fe3496e11bc935e72cbf9b18504442e/gensim/models/word2vec.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.7 s, sys: 84 ms, total: 14.8 s\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "# lockf=0 doesn't train word vectors any further, 1.0 does.\n",
    "%time word2vec.intersect_word2vec_format(\"dataset/glove.6B.50d.word2vec.txt\", lockf=1.0, binary=False, encoding='utf8', unicode_errors='strict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 32s, sys: 1.53 s, total: 5min 33s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%time model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pretrained = Doc2Vec(vector_size=50, min_count=2, workers=4)\n",
    "model_pretrained.build_vocab(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 54s, sys: 1.9 s, total: 5min 56s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "model_pretrained.wv = word2vec.wv\n",
    "%time model_pretrained.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>release_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Star Wars: Episode III - Revenge of the Sith</td>\n",
       "      <td>1895</td>\n",
       "      <td>2005-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Star Wars: Episode II - Attack of the Clones</td>\n",
       "      <td>1894</td>\n",
       "      <td>2002-05-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Star Wars: Episode I - The Phantom Menace</td>\n",
       "      <td>1893</td>\n",
       "      <td>1999-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>Star Wars</td>\n",
       "      <td>11</td>\n",
       "      <td>1977-05-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title    id release_date\n",
       "204   Star Wars: Episode III - Revenge of the Sith  1895   2005-05-17\n",
       "205   Star Wars: Episode II - Attack of the Clones  1894   2002-05-15\n",
       "208      Star Wars: Episode I - The Phantom Menace  1893   1999-05-19\n",
       "2199                                     Star Wars    11   1977-05-25"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.title.str.lower().str.contains(\"star wars\")][[\n",
    "    \"title\", \"id\", \"release_date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id = 1894"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = subs[movie_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Star Wars: Episode II - Attack of the Clones</td>\n",
       "      <td>1894</td>\n",
       "      <td>2002-05-15</td>\n",
       "      <td>0.937870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Star Wars: Episode III - Revenge of the Sith</td>\n",
       "      <td>1895</td>\n",
       "      <td>2005-05-17</td>\n",
       "      <td>0.929543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Return of the Jedi</td>\n",
       "      <td>1892</td>\n",
       "      <td>1983-05-23</td>\n",
       "      <td>0.884209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Star Wars: Episode I - The Phantom Menace</td>\n",
       "      <td>1893</td>\n",
       "      <td>1999-05-19</td>\n",
       "      <td>0.872506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Black Hole</td>\n",
       "      <td>9570</td>\n",
       "      <td>1979-12-18</td>\n",
       "      <td>0.851249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Star Trek III: The Search for Spock</td>\n",
       "      <td>157</td>\n",
       "      <td>1984-05-31</td>\n",
       "      <td>0.816023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>John Carter</td>\n",
       "      <td>49529</td>\n",
       "      <td>2012-03-07</td>\n",
       "      <td>0.815593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Empire Strikes Back</td>\n",
       "      <td>1891</td>\n",
       "      <td>1980-05-17</td>\n",
       "      <td>0.799171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Star Wars</td>\n",
       "      <td>11</td>\n",
       "      <td>1977-05-25</td>\n",
       "      <td>0.793723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stargate: The Ark of Truth</td>\n",
       "      <td>13001</td>\n",
       "      <td>2008-03-11</td>\n",
       "      <td>0.787915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title     id release_date  \\\n",
       "0  Star Wars: Episode II - Attack of the Clones   1894   2002-05-15   \n",
       "1  Star Wars: Episode III - Revenge of the Sith   1895   2005-05-17   \n",
       "2                            Return of the Jedi   1892   1983-05-23   \n",
       "3     Star Wars: Episode I - The Phantom Menace   1893   1999-05-19   \n",
       "4                                The Black Hole   9570   1979-12-18   \n",
       "5           Star Trek III: The Search for Spock    157   1984-05-31   \n",
       "6                                   John Carter  49529   2012-03-07   \n",
       "7                       The Empire Strikes Back   1891   1980-05-17   \n",
       "8                                     Star Wars     11   1977-05-25   \n",
       "9                    Stargate: The Ark of Truth  13001   2008-03-11   \n",
       "\n",
       "   similarity  \n",
       "0    0.937870  \n",
       "1    0.929543  \n",
       "2    0.884209  \n",
       "3    0.872506  \n",
       "4    0.851249  \n",
       "5    0.816023  \n",
       "6    0.815593  \n",
       "7    0.799171  \n",
       "8    0.793723  \n",
       "9    0.787915  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferred_vector = model.infer_vector(words, steps=20)\n",
    "similar = model.docvecs.most_similar([inferred_vector], topn=10)\n",
    "pd.DataFrame({\"id\": [x[0] for x in similar],\n",
    "              \"similarity\": [x[1] for x in similar]}).merge(df)[[\"title\", \"id\", \"release_date\", \"similarity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Star Wars: Episode II - Attack of the Clones</td>\n",
       "      <td>1894</td>\n",
       "      <td>2002-05-15</td>\n",
       "      <td>0.939697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Star Wars: Episode III - Revenge of the Sith</td>\n",
       "      <td>1895</td>\n",
       "      <td>2005-05-17</td>\n",
       "      <td>0.924172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Return of the Jedi</td>\n",
       "      <td>1892</td>\n",
       "      <td>1983-05-23</td>\n",
       "      <td>0.902013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Star Wars: Episode I - The Phantom Menace</td>\n",
       "      <td>1893</td>\n",
       "      <td>1999-05-19</td>\n",
       "      <td>0.858750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Star Trek III: The Search for Spock</td>\n",
       "      <td>157</td>\n",
       "      <td>1984-05-31</td>\n",
       "      <td>0.802331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Star Trek VI: The Undiscovered Country</td>\n",
       "      <td>174</td>\n",
       "      <td>1991-12-05</td>\n",
       "      <td>0.799173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stargate: The Ark of Truth</td>\n",
       "      <td>13001</td>\n",
       "      <td>2008-03-11</td>\n",
       "      <td>0.794862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Empire Strikes Back</td>\n",
       "      <td>1891</td>\n",
       "      <td>1980-05-17</td>\n",
       "      <td>0.789949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Star Wars</td>\n",
       "      <td>11</td>\n",
       "      <td>1977-05-25</td>\n",
       "      <td>0.787847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Warcraft</td>\n",
       "      <td>68735</td>\n",
       "      <td>2016-05-25</td>\n",
       "      <td>0.787183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title     id release_date  \\\n",
       "0  Star Wars: Episode II - Attack of the Clones   1894   2002-05-15   \n",
       "1  Star Wars: Episode III - Revenge of the Sith   1895   2005-05-17   \n",
       "2                            Return of the Jedi   1892   1983-05-23   \n",
       "3     Star Wars: Episode I - The Phantom Menace   1893   1999-05-19   \n",
       "4           Star Trek III: The Search for Spock    157   1984-05-31   \n",
       "5        Star Trek VI: The Undiscovered Country    174   1991-12-05   \n",
       "6                    Stargate: The Ark of Truth  13001   2008-03-11   \n",
       "7                       The Empire Strikes Back   1891   1980-05-17   \n",
       "8                                     Star Wars     11   1977-05-25   \n",
       "9                                      Warcraft  68735   2016-05-25   \n",
       "\n",
       "   similarity  \n",
       "0    0.939697  \n",
       "1    0.924172  \n",
       "2    0.902013  \n",
       "3    0.858750  \n",
       "4    0.802331  \n",
       "5    0.799173  \n",
       "6    0.794862  \n",
       "7    0.789949  \n",
       "8    0.787847  \n",
       "9    0.787183  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferred_vector = model_pretrained.infer_vector(words, steps=20)\n",
    "similar = model_pretrained.docvecs.most_similar([inferred_vector], topn=10)\n",
    "pd.DataFrame({\"id\": [x[0] for x in similar],\n",
    "              \"similarity\": [x[1] for x in similar]})\\\n",
    "    .merge(df)[[\"title\", \"id\", \"release_date\", \"similarity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_docvecs(df):\n",
    "    docvecs = []\n",
    "    for index in tqdm(df.id.tolist()):\n",
    "        word_list = subs[index]\n",
    "        vec = model_pretrained.infer_vector(word_list, steps=20)\n",
    "        docvecs.append(vec)\n",
    "    docvecs = np.array(docvecs, dtype=np.float32)\n",
    "    return docvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list(cell):\n",
    "    \"\"\"convert the json format to a list of categories\"\"\"\n",
    "    kw_list = []\n",
    "    for kw in json.loads(cell):\n",
    "        kw_list.append(kw['name'])\n",
    "    return kw_list\n",
    "\n",
    "\n",
    "def larger_n(col, n):\n",
    "    \"\"\"filter the column\"\"\"\n",
    "    keywords = defaultdict(int)\n",
    "    for row in df[col]:\n",
    "        row = json.loads(row)\n",
    "        for entry in row:\n",
    "            keywords[entry['name']] += 1\n",
    "    kw_cnt = sorted(keywords.items(), key=lambda x: -x[1])\n",
    "    return [kw[0] for kw in kw_cnt if kw[1] >= n]\n",
    "\n",
    "\n",
    "def extract_gender(cell):\n",
    "    \"\"\"Extract cast gender\"\"\"\n",
    "    female = 0\n",
    "    male = 0\n",
    "    for item in json.loads(cell):\n",
    "        if item['gender'] == 1:\n",
    "            female += 1\n",
    "        elif item['gender'] == 2:\n",
    "            male += 1\n",
    "        else:\n",
    "            continue\n",
    "    return female, male\n",
    "\n",
    "\n",
    "def concat_names(cell):\n",
    "    \"\"\"Concatenate first names and last names\"\"\"\n",
    "    names = []\n",
    "    for name in cell:\n",
    "        names.append(name.replace(' ', ''))\n",
    "    return names\n",
    "\n",
    "\n",
    "def list2str(cell):\n",
    "    \"\"\"Convert list to string\"\"\"\n",
    "    return ' '.join(cell)\n",
    "\n",
    "\n",
    "def transform_cols(df, cols_to_transform):\n",
    "    \"\"\"Transform columns of a dataframe.\n",
    "    cols_to_transform should be a dict(col_name: filter value n)\n",
    "    \"\"\"\n",
    "    for col_name in cols_to_transform.keys():\n",
    "        larger_col = larger_n(col_name, cols_to_transform[col_name])\n",
    "        if col_name == 'cast':\n",
    "            gen = df[col_name].apply(extract_gender)\n",
    "            df['female_pct'] = gen.apply(lambda x: x[0]/(x[0]+x[1]+0.001))\n",
    "            df['male_pct'] = gen.apply(lambda x: x[1]/(x[0]+x[1]+0.001))\n",
    "\n",
    "        df[col_name] = df[col_name].apply(convert_list)\\\n",
    "            .apply(lambda cell: [kw for kw in cell if kw in larger_col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_transform = {'keywords': 30,\n",
    "                     'genres': 0,\n",
    "                     'production_companies': 5,\n",
    "                     'production_countries': 3,\n",
    "                     'spoken_languages': 10,\n",
    "                     'cast': 2}\n",
    "\n",
    "df_movies = transform_cols(df, cols_to_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer(classes=None, sparse_output=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(df_movies['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7912413566019098, 0.20875864339809022)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.release_date = pd.to_datetime(df.release_date)\n",
    "df.release_date.max(), df.release_date.min()\n",
    "split_date = datetime.datetime(2012, 1, 1)\n",
    "train_df = df[df.release_date < split_date]\n",
    "test_df = df[df.release_date >= split_date]\n",
    "\n",
    "train_genres_dummies = pd.DataFrame(mlb.transform(\n",
    "    train_df['genres']), columns=mlb.classes_).add_prefix('genre_')\n",
    "\n",
    "test_genres_dummies = pd.DataFrame(mlb.transform(\n",
    "    test_df['genres']), columns=mlb.classes_).add_prefix('genre_')\n",
    "\n",
    "train_df.shape[0]/df.shape[0], test_df.shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2403/2403 [11:54<00:00,  3.37it/s]\n",
      "100%|██████████| 634/634 [02:31<00:00,  4.36it/s]\n"
     ]
    }
   ],
   "source": [
    "train_docvecs = infer_docvecs(train_df)\n",
    "test_docvecs = infer_docvecs(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_docvecs, test_docvecs\n",
    "train_labels, test_labels = train_genres_dummies, test_genres_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "parameters = {'n_estimators': [100],\n",
    "              'min_samples_leaf': [2],\n",
    "              # 'criterion': ['gini', 'entropy'],\n",
    "              'max_depth': [None, 5, 20, 40],\n",
    "              'min_samples_split': [2]}\n",
    "\n",
    "rf = GridSearchCV(RandomForestClassifier(verbose=1, n_jobs=4,\n",
    "                                         oob_score=True), cv=3, param_grid=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.6 s, sys: 112 ms, total: 39.7 s\n",
      "Wall time: 35.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=4,\n",
       "            oob_score=True, random_state=None, verbose=1, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [100], 'min_samples_leaf': [2], 'max_depth': [None, 5, 20, 40], 'min_samples_split': [2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time rf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 40,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6729088639200999\n",
      "\n",
      "Test accuracy: 0.14353312302839116\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         Action       0.73      0.51      0.60       176\n",
      "      Adventure       0.80      0.26      0.40       125\n",
      "      Animation       1.00      0.05      0.09        41\n",
      "         Comedy       0.71      0.63      0.66       202\n",
      "          Crime       0.73      0.17      0.28        92\n",
      "    Documentary       0.00      0.00      0.00         7\n",
      "          Drama       0.64      0.50      0.56       259\n",
      "         Family       0.93      0.38      0.54        65\n",
      "        Fantasy       0.67      0.03      0.06        65\n",
      "        Foreign       0.00      0.00      0.00         1\n",
      "        History       0.00      0.00      0.00        15\n",
      "         Horror       1.00      0.07      0.13        83\n",
      "          Music       0.00      0.00      0.00        25\n",
      "        Mystery       0.00      0.00      0.00        35\n",
      "        Romance       0.59      0.22      0.32        72\n",
      "Science Fiction       0.81      0.25      0.39        83\n",
      "       TV Movie       0.00      0.00      0.00         1\n",
      "       Thriller       0.68      0.46      0.54       193\n",
      "            War       0.00      0.00      0.00        11\n",
      "        Western       0.00      0.00      0.00         8\n",
      "\n",
      "      micro avg       0.70      0.36      0.47      1559\n",
      "      macro avg       0.46      0.18      0.23      1559\n",
      "   weighted avg       0.69      0.36      0.43      1559\n",
      "    samples avg       0.57      0.40      0.44      1559\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julia/MSDS/Fall18/msds621/miniconda/envs/ml/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/julia/MSDS/Fall18/msds621/miniconda/envs/ml/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "train_predictions = rf.predict(train_data)\n",
    "predictions = rf.predict(test_data)\n",
    "\n",
    "print(f\"Train accuracy: {accuracy_score(train_labels, train_predictions)}\\n\")\n",
    "print(f\"Test accuracy: {accuracy_score(test_labels, predictions)}\\n\")\n",
    "\n",
    "print(classification_report(test_labels, predictions, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Hamming Loss: 0.021306699958385352\n",
      "\n",
      "Hamming Loss: 0.09755520504731861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "print(f\"Train Hamming Loss: {hamming_loss(train_labels, train_predictions)}\\n\")\n",
    "print(f\"Hamming Loss: {hamming_loss(test_labels, predictions)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
